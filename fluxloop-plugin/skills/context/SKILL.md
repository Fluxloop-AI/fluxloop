---
name: fluxloop-context
description: |
  Use for scanning the codebase and creating/updating the agent profile.
  Frequency: once initially, then only when agent code changes. Stale detection handles this automatically.
  Keywords: context, profile, scan, update profile, agent info

  Auto-activates on requests like:
  - "scan the agent", "analyze the agent"
  - "update profile", "refresh profile"
  - "what does this agent do?"
---

# FluxLoop Context Skill

**Scan-Summarize-Save**: Codebase scan â†’ Profile summary â†’ Server upload + Local save (Dual Write)

## Output Format

> ğŸ“ All user-facing output must follow: read skills/_shared/OUTPUT_FORMAT.md

## Context Protocol

1. `fluxloop context show` â†’ confirm project is set up
2. `.fluxloop/test-memory/` check:
   - Exists â†’ load `agent-profile.md` (show existing profile)
   - Missing â†’ create `.fluxloop/test-memory/` directory (first run)
3. Dual Write:
   - Server: `fluxloop data push` (upload key files)
   - Local: save to `.fluxloop/test-memory/agent-profile.md` with metadata
4. On completion: verify `agent-profile.md` is current (`git_commit` matches)

> ğŸ“ Full protocol: read skills/_shared/CONTEXT_PROTOCOL.md
> ğŸ“ Collection procedure: read skills/_shared/CONTEXT_COLLECTION.md

## Prerequisite

Run `fluxloop context show` first:
- âœ… Project selected â†’ proceed
- âŒ No project â†’ Prerequisite Resolution (ğŸ“ read skills/_shared/PREREQUISITE_RESOLUTION.md):
  - "Project setup is required. Would you like to run setup first?"
  - Approved: ğŸ“ Run `skills/setup/SKILL.md` inline â†’ on completion "âœ… Setup complete. Continuing with context." â†’ return to Step 1
  - Denied: stop

## Workflow

> âš ï¸ Each Step must be executed sequentially. Do not batch Bash/Read calls in parallel. (ğŸ“ See CONTEXT_PROTOCOL.md)

### Step 1: Check Existing Profile

Check if `.fluxloop/test-memory/agent-profile.md` exists.

**If exists**:
- Show existing profile summary
- Display `scan_date` and `git_commit` from metadata
- Ask: "Would you like to update the profile? (Yes/No)"
  - No â†’ keep existing profile, go to Next Steps
  - Yes â†’ proceed to Step 2

**If missing**: "This is the first scan." â†’ proceed to Step 2

### Step 2: Codebase Scan

> ğŸ“ Follow the collection procedure: read skills/_shared/CONTEXT_COLLECTION.md

Scan targets:
1. README.md (or README.rst, README)
2. Agent main file (file containing system prompt, tool definitions)
3. package.json / pyproject.toml / requirements.txt (dependencies)
4. API spec files (OpenAPI, GraphQL schema, etc.)
5. Test files (to understand existing test structure)

Structure the scan results:
- Agent name, role
- LLM model / provider
- System prompt summary (3-5 lines)
- Tools / API list (table)
- Key features (bullet list)
- Dependencies (key packages / services)

### Step 3: Interactive â€” Additional Documents

Ask: "Do you have any reference documents or validation data? (enter path / skip)"
- Path entered â†’ classify using the decision tree in Step 5-1:
  - Classified as GT but no scenario exists â†’ "This file looks like validation data (Ground Truth). It will be uploaded as context for now. After creating a scenario, you can bind it as Ground Truth."
  - Classified as GT with active scenario â†’ include for GT upload in Step 5-3
  - Classified as context â†’ include for context upload in Step 5-2
- skip â†’ proceed

### Step 4: Intent Refine (Upload project context to server)

Refine and send the project intent to the FluxLoop server based on scan results from Step 2.

> ğŸ’¡ **What is Intent Refine?** This step summarizes the agent's purpose, capabilities, and tech stack into a format the server can understand and transmit it. The server analyzes this information to improve scenario generation and test quality.

```bash
fluxloop intent refine --intent "<1-3 sentence summary of agent purpose and key capabilities>"
```

- `--intent` parameter: auto-generated based on Step 2 scan results (agent role, key features, tech stack)
- Server analyzes/refines the intent and stores it â†’ used in subsequent scenario/test steps
- Success response: "âœ“ Intent extracted successfully"
- On failure: display error and proceed to Step 5 (intent upload failure does not block the workflow)

> ğŸ“ Staging environment: read skills/_shared/STAGING.md (add `--staging` flag for staging environments)

### Step 5: Server Upload (Dual Write â€” Server)

Upload key files to the server. Before uploading, classify each file as **Context** or **Ground Truth**.

#### 5-1. Data Classification Decision Tree

> ğŸ’¡ **Context vs Ground Truth**: Context data is reference material that informs test generation (e.g., docs, specs, code). Ground Truth (GT) data is a structured dataset with expected answers used to validate agent output correctness after test execution.

For each file the user provides, apply this decision tree **in order**:

```
File to upload
  â”‚
  â”œâ”€ 1. User explicitly says "ground truth", "validation data",
  â”‚     "expected answers", "ì •ë‹µ ë°ì´í„°", "ê²€ì¦ ë°ì´í„°"
  â”‚     â†’ âœ… Ground Truth
  â”‚
  â”œâ”€ 2. User explicitly says "context", "reference", "ì°¸ê³  ìë£Œ"
  â”‚     â†’ âœ… Context
  â”‚
  â”œâ”€ 3. Check file type:
  â”‚     â”‚
  â”‚     â”œâ”€ Unstructured (md, txt, pdf, docx, html)
  â”‚     â”‚   â†’ âœ… Context (always)
  â”‚     â”‚
  â”‚     â””â”€ Structured (csv, json, jsonl, xlsx, tsv)
  â”‚         â”‚
  â”‚         â”œâ”€ 4. Inspect content â€” does it have input+output column pairs?
  â”‚         â”‚     (e.g., "question"+"answer", "input"+"expected_output",
  â”‚         â”‚      "query"+"label", "prompt"+"response")
  â”‚         â”‚     â†’ YES â†’ âœ… Ground Truth (confirm with user)
  â”‚         â”‚     â†’ NO or UNCLEAR â†’ Step 5
  â”‚         â”‚
  â”‚         â””â”€ 5. Ask the user:
  â”‚               "ì´ íŒŒì¼ì€ êµ¬ì¡°í™”ëœ ë°ì´í„°ì…ë‹ˆë‹¤. ìš©ë„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
  â”‚                1) ì°¸ê³  ìë£Œ (Context) â€” í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± ì‹œ ì°¸ê³ ìš©
  â”‚                2) ì •ë‹µ ë°ì´í„° (Ground Truth) â€” ì—ì´ì „íŠ¸ ì¶œë ¥ì˜ ì •í™•ì„± ê²€ì¦ìš©"
```

**Key distinction**:

| Aspect | Context | Ground Truth |
|--------|---------|--------------|
| Purpose | Informs input synthesis quality | Validates output correctness |
| File types | Any (md, pdf, csv, etc.) | Structured only (csv, json, jsonl, xlsx) |
| Requires scenario | No (project library) | Yes (must bind to scenario) |
| Has labels/answers | No | Yes (input + expected output columns) |
| Examples | README, API spec, user guide | Q&A pairs, expected outputs, scoring rubrics |

#### 5-2. Context Upload (default)

```bash
fluxloop data push README.md
fluxloop data push <agent-main-file> --bind
```

- `--bind` links the file to the current scenario (use only when a scenario is selected)
- If no scenario exists, upload to the project library without `--bind`

#### 5-3. Ground Truth Upload

> âš ï¸ GT upload requires an active scenario. If no scenario exists, skip GT upload and note: "Ground Truth data can be added after scenario creation (scenario skill)."

```bash
fluxloop data push <gt-file> --usage ground-truth --scenario <scenario_id> \
  --label-column <col>
```

**GT options**:

| Option | Required | Description |
|--------|----------|-------------|
| `--usage ground-truth` | Yes | Activates GT mode (forces DATASET category) |
| `--scenario <id>` or `--bind` | Yes | GT must be bound to a scenario |
| `--label-column <col>` | Recommended | Column containing expected answers |
| `--split <train\|dev\|test>` | No | Data split |
| `--row-filter <expr>` | No | Filter rows before materialization |
| `--sampling-seed <N>` | No | Reproducibility seed (default: 42) |

After successful GT upload, the CLI auto-materializes GT profile and contracts. Display:

```
âœ… Data (GT) â†’ {filename} uploaded + bound to scenario
  data_id: {data_id}
  profile_id: {profile_id}
  gt_contract_count: {N}
```

> **Required result output**: After all uploads, display: `âœ… Data â†’ N files uploaded to project library` (+ GT summary if applicable)
> (Data actions have no URL â€” see POST_ACTIONS.md)

### Step 6: Local Save (Dual Write â€” Local)

Ensure `.fluxloop/test-memory/` directory exists (create if missing).

Save to `.fluxloop/test-memory/agent-profile.md`:
- Metadata: `<!-- scan_date: {current ISO8601} | git_commit: {git rev-parse --short HEAD} -->`
- Format: follow the template from `test-memory-template/agent-profile.md`
- Replace all placeholders with actual scan results

### Step 7: Profile Summary Output

Show the generated profile to the user:
- Key info: agent name, role, LLM, number of tools, key features
- Ask: "Does this profile look correct? Let me know if anything needs to be changed."

## Error Handling

| Error | Response |
|-------|----------|
| Project not set up | Apply Prerequisite Resolution â†’ suggest inline setup execution |
| No README found | Fall back to other files (pyproject.toml, main file); create a limited profile |
| `fluxloop intent refine` failure | Log error, proceed to next step (best-effort â€” does not block workflow) |
| `fluxloop data push` failure | Check network, verify file path, confirm login status |
| GT upload without scenario | "Ground Truth requires a scenario. Create one first (scenario skill), then upload with `--usage ground-truth`." |
| GT materialization 409 | "Check status: `fluxloop data gt status --scenario <id>`. Retry bind after processing completes." |
| `git rev-parse` failure (not a git repo) | Set `git_commit` to `no-git`; note that stale detection is unavailable |

## Next Steps

Profile ready. Available next action:
- Scenario creation tailored to the agent profile (scenario skill)

## Quick Reference

| Step | Command |
|------|---------|
| Check | `fluxloop context show` |
| Intent | `fluxloop intent refine --intent "..."` |
| Upload | `fluxloop data push <file>` |
| Upload + bind | `fluxloop data push <file> --bind` |
| Upload (GT) | `fluxloop data push <file> --usage ground-truth --scenario <id> --label-column <col>` |
| GT status | `fluxloop data gt status --scenario <id>` |
| Git hash | `git rev-parse --short HEAD` |

> ğŸ“ Full CLI reference: read skills/_shared/QUICK_REFERENCE.md

## Key Rules

1. Always check existing `agent-profile.md` before scanning â€” avoid redundant work
2. Use the template from `test-memory-template/agent-profile.md` for output format
3. Include metadata comment (`scan_date`, `git_commit`) â€” required for stale detection
4. Dual Write: server upload (`data push`) and local save (`agent-profile.md`) at the same time
5. Use `--bind` only when a scenario is already selected
6. Ask for additional reference documents in interactive mode
7. If no git repo, set `git_commit: no-git` and note stale detection is unavailable
8. Show profile summary and ask for confirmation before finalizing
9. On update: overwrite the entire `agent-profile.md` (not append)
10. Classify files before upload: unstructured â†’ context; structured with input+output pairs â†’ likely GT (confirm with user)
11. GT upload requires an active scenario â€” defer GT files if no scenario exists
